{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chinese-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://github.com/pytorch/vision/blob/master/torchvision/models/detection/backbone_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exotic-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork, LastLevelMaxPool\n",
    "\n",
    "from torchvision.ops import misc as misc_nn_ops\n",
    "from torchvision.models._utils import IntermediateLayerGetter\n",
    "from torchvision.models import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "solar-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackboneWithFPN(nn.Module):\n",
    "    \"\"\"\n",
    "    Adds a FPN on top of a model.\n",
    "    Internally, it uses torchvision.models._utils.IntermediateLayerGetter to\n",
    "    extract a submodel that returns the feature maps specified in return_layers.\n",
    "    The same limitations of IntermediatLayerGetter apply here.\n",
    "    Args:\n",
    "        backbone (nn.Module)\n",
    "        return_layers (Dict[name, new_name]): a dict containing the names\n",
    "            of the modules for which the activations will be returned as\n",
    "            the key of the dict, and the value of the dict is the name\n",
    "            of the returned activation (which the user can specify).\n",
    "        in_channels_list (List[int]): number of channels for each feature map\n",
    "            that is returned, in the order they are present in the OrderedDict\n",
    "        out_channels (int): number of channels in the FPN.\n",
    "    Attributes:\n",
    "        out_channels (int): the number of channels in the FPN\n",
    "    \"\"\"\n",
    "    def __init__(self, backbone, return_layers, in_channels_list, out_channels, extra_blocks=None):\n",
    "        super(BackboneWithFPN, self).__init__()\n",
    "\n",
    "        if extra_blocks is None:\n",
    "            extra_blocks = LastLevelMaxPool()\n",
    "\n",
    "        self.body = IntermediateLayerGetter(backbone, return_layers=return_layers)\n",
    "        self.fpn = FeaturePyramidNetwork(\n",
    "            in_channels_list=in_channels_list,\n",
    "            out_channels=out_channels,\n",
    "            extra_blocks=extra_blocks,\n",
    "        )\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        x = self.fpn(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def resnet_fpn_backbone(\n",
    "    backbone_name,\n",
    "    pretrained,\n",
    "    norm_layer=misc_nn_ops.FrozenBatchNorm2d,\n",
    "    trainable_layers=3,\n",
    "    returned_layers=None,\n",
    "    extra_blocks=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Constructs a specified ResNet backbone with FPN on top. Freezes the specified number of layers in the backbone.\n",
    "    Args:\n",
    "        backbone_name (string): resnet architecture. Possible values are 'ResNet', 'resnet18', 'resnet34', 'resnet50',\n",
    "             'resnet101', 'resnet152', 'resnext50_32x4d', 'resnext101_32x8d', 'wide_resnet50_2', 'wide_resnet101_2'\n",
    "        pretrained (bool): If True, returns a model with backbone pre-trained on Imagenet\n",
    "        norm_layer (torchvision.ops): it is recommended to use the default value. For details visit:\n",
    "            (https://github.com/facebookresearch/maskrcnn-benchmark/issues/267)\n",
    "        trainable_layers (int): number of trainable (not frozen) resnet layers starting from final block.\n",
    "            Valid values are between 0 and 5, with 5 meaning all backbone layers are trainable.\n",
    "        returned_layers (list of int): The layers of the network to return. Each entry must be in ``[1, 4]``.\n",
    "            By default all layers are returned.\n",
    "        extra_blocks (ExtraFPNBlock or None): if provided, extra operations will\n",
    "            be performed. It is expected to take the fpn features, the original\n",
    "            features and the names of the original features as input, and returns\n",
    "            a new list of feature maps and their corresponding names. By\n",
    "            default a ``LastLevelMaxPool`` is used.\n",
    "    \"\"\"\n",
    "    backbone = resnet.__dict__[backbone_name](\n",
    "        pretrained=pretrained,\n",
    "        norm_layer=norm_layer)\n",
    "\n",
    "    # select layers that wont be frozen\n",
    "    assert 0 <= trainable_layers <= 5\n",
    "    layers_to_train = ['layer4', 'layer3', 'layer2', 'layer1', 'conv1'][:trainable_layers]\n",
    "    if trainable_layers == 5:\n",
    "        layers_to_train.append('bn1')\n",
    "    for name, parameter in backbone.named_parameters():\n",
    "        if all([not name.startswith(layer) for layer in layers_to_train]):\n",
    "            parameter.requires_grad_(False)\n",
    "\n",
    "    if extra_blocks is None:\n",
    "        extra_blocks = LastLevelMaxPool()\n",
    "\n",
    "    if returned_layers is None:\n",
    "        returned_layers = [1, 2, 3, 4]\n",
    "    assert min(returned_layers) > 0 and max(returned_layers) < 5\n",
    "    return_layers = {f'layer{k}': str(v) for v, k in enumerate(returned_layers)}\n",
    "\n",
    "    in_channels_stage2 = backbone.inplanes // 8\n",
    "    in_channels_list = [in_channels_stage2 * 2 ** (i - 1) for i in returned_layers]\n",
    "    out_channels = 256\n",
    "    return BackboneWithFPN(backbone, return_layers, in_channels_list, out_channels, extra_blocks=extra_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "blocked-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    import torch\n",
    "    backbone = resnet_fpn_backbone('resnet50', pretrained=True, trainable_layers=3)\n",
    "    # get some dummy image\n",
    "    x = torch.rand(1,3,64,64)\n",
    "    # compute the output\n",
    "    output = backbone(x)\n",
    "    print([(k, v.shape) for k, v in output.items()])\n",
    "    \n",
    "# check returns\n",
    "# [('0', torch.Size([1, 256, 16, 16])),\n",
    "#  ('1', torch.Size([1, 256, 8, 8])),\n",
    "#  ('2', torch.Size([1, 256, 4, 4])),\n",
    "#  ('3', torch.Size([1, 256, 2, 2])),\n",
    "#  ('pool', torch.Size([1, 256, 1, 1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "early-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0', torch.Size([1, 256, 16, 16])), ('1', torch.Size([1, 256, 8, 8])), ('2', torch.Size([1, 256, 4, 4])), ('3', torch.Size([1, 256, 2, 2])), ('pool', torch.Size([1, 256, 1, 1]))]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai604",
   "language": "python",
   "name": "ai604"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
