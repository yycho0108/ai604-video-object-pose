{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import io\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "\n",
    "# imports the torch_xla package\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "\n",
    "import torch_xla.distributed.data_parallel as dp\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.utils.tf_record_reader as tfrr\n",
    "\n",
    "NUM_KEYPOINTS = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glob_objectron():\n",
    "    client = storage.Client.create_anonymous_client()\n",
    "    blobs = client.list_blobs('objectron',\n",
    "                              prefix='v1/records_shuffled/cup/cup_train')\n",
    "    return [blob.name for blob in blobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_objectron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(example):\n",
    "  \"\"\" Convert TFRecord Entry into torch-compatible format \"\"\"\n",
    "  w = example['image/width'].item()\n",
    "  h = example['image/height'].item()\n",
    "  points = example['point_2d'].numpy()\n",
    "  num_instances = example['instance_num'].item()\n",
    "  points = points.reshape(num_instances, NUM_KEYPOINTS, 3)\n",
    "  image_data = example['image/encoded'].numpy().tobytes()\n",
    "  image = Image.open(io.BytesIO(image_data))\n",
    "  npa = np.asarray(image)\n",
    "  return torch.from_numpy(npa), points, num_instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# https://stackoverflow.com/questions/11159436/multiple-figures-in-a-single-window\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0,0], [1,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RADIUS = 10\n",
    "\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (128, 128, 0), (128, 0, 128), \n",
    "          (0, 128, 128), (255, 255, 255), (0, 0, 0)]\n",
    "EDGES = [\n",
    "  [1, 5], [2, 6], [3, 7], [4, 8],  # lines along x-axis\n",
    "  [1, 3], [5, 7], [2, 4], [6, 8],  # lines along y-axis\n",
    "  [1, 2], [3, 4], [5, 6], [7, 8]   # lines along z-axis\n",
    "]  \n",
    "\n",
    "def load_dataset():\n",
    "    r = tfrr.TfRecordReader(path, compression='', transforms=transforms)\n",
    "    for i in range(num_samples):\n",
    "        example = r.read_example()\n",
    "        img_tensor, keypoints, num_instances = decode(example)\n",
    "\n",
    "\n",
    "def show_3d_bounding_box(path, num_samples):\n",
    "  count = 0\n",
    "  transforms = {}  \n",
    "  r = tfrr.TfRecordReader(path, compression='', transforms=transforms)\n",
    "  fig, ax = plt.subplots(1, 10, figsize = (12, 16))\n",
    "  \n",
    "  for i in range(num_samples):\n",
    "    example = r.read_example()\n",
    "    if not example: break\n",
    "    img_tensor, keypoints, num_instances = decode(example)\n",
    "    image_clone = img_tensor\n",
    "\n",
    "    for object_id in range(num_instances):\n",
    "      w = 480\n",
    "      h = 640\n",
    "      for kp_id in range(NUM_KEYPOINTS):\n",
    "        kp_pixel = keypoints[object_id, kp_id, :]\n",
    "        cv2.circle(image_clone.numpy(), (int(w  * kp_pixel[0]), int(h * kp_pixel[1])), \n",
    "                  RADIUS, colors[object_id % len(colors)], -1)\n",
    "      for edge in EDGES:\n",
    "        start_kp = keypoints[object_id, edge[0], :]\n",
    "        start_x = int(w * start_kp[0])\n",
    "        start_y = int(h * start_kp[1])\n",
    "        \n",
    "        end_kp = keypoints[object_id, edge[1], :]\n",
    "        end_x = int(w * end_kp[0])\n",
    "        end_y = int(h * end_kp[1])\n",
    "\n",
    "        cv2.line(image_clone.numpy(), (start_x, start_y), (end_x, end_y), \n",
    "                  colors[object_id % len(colors)], 1)\n",
    "    ax[i].grid(False)\n",
    "    ax[i].imshow(image_clone);\n",
    "    ax[i].get_xaxis().set_visible(False)\n",
    "    ax[i].get_yaxis().set_visible(False)\n",
    "\n",
    "  fig.tight_layout();\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_shards = glob_objectron()\n",
    "for i in range(5):\n",
    "  shard_name = 'gs://objectron/' + training_shards[i]\n",
    "  print(shard_name)\n",
    "  # Visualize the bounding box on the first 10 sample from this shard.\n",
    "  show_3d_bounding_box(path = shard_name, num_samples = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "th_env",
   "language": "python",
   "name": "th_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
